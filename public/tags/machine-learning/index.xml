<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Machine Learning on Franz Louis Cesista</title>
    <link>https://leloykun.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Franz Louis Cesista</description>
    <generator>Hugo -- 0.125.4</generator>
    <language>en</language>
    <lastBuildDate>Thu, 27 Feb 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://leloykun.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Steepest Descent Under Schatten-p Norms</title>
      <link>https://leloykun.github.io/ponder/steepest-descent-schatten-p/</link>
      <pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/ponder/steepest-descent-schatten-p/</guid>
      <description>Why Muon still work despite not perfectly semi-orthogonalizing the gradients.</description>
    </item>
    <item>
      <title>Squeezing 1-2% Efficiency Gains Out of Muon by Optimizing the Newton-Schulz Coefficients</title>
      <link>https://leloykun.github.io/ponder/muon-opt-coeffs/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/ponder/muon-opt-coeffs/</guid>
      <description>Simply switching to Muon can already get you 2x efficiency gains. But you can squeeze out an extra 1-2% by optimizing the Newton-Schulz coefficients.</description>
    </item>
    <item>
      <title>CASPR Without Accumulation is Muon</title>
      <link>https://leloykun.github.io/ponder/caspr-wo-accum-is-muon/</link>
      <pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/ponder/caspr-wo-accum-is-muon/</guid>
      <description>The CASPR optimizer, a variant of Shampoo, reduces to Muon when we remove the accumulation on the preconditioners.</description>
    </item>
    <item>
      <title>GRPO&#39;s Main Flaw</title>
      <link>https://leloykun.github.io/ponder/grpo-flaw/</link>
      <pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/ponder/grpo-flaw/</guid>
      <description>GRPO may not be the best choice for training reasoning models. Here&amp;#39;s why.</description>
    </item>
    <item>
      <title>(Linear) Attention as Test-Time Regression</title>
      <link>https://leloykun.github.io/ponder/test-time-regression/</link>
      <pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/ponder/test-time-regression/</guid>
      <description>A unifying framework for linear attention mechanisms as test-time regression and how to parallelize training and inference.</description>
    </item>
    <item>
      <title>Deep Learning Optimizers as Steepest Descent in Normed Spaces</title>
      <link>https://leloykun.github.io/ponder/steepest-descent-opt/</link>
      <pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/ponder/steepest-descent-opt/</guid>
      <description>Instead of asking, &amp;#39;Which optimizer should I use?&amp;#39; ask, &amp;#39;In which space do my features live in?&amp;#39;</description>
    </item>
    <item>
      <title>Multimodal Structured Generation</title>
      <link>https://leloykun.github.io/personal-projects/mmsg/</link>
      <pubDate>Sun, 14 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/personal-projects/mmsg/</guid>
      <description>Generate interleaved text and image content in a structured format you can directly pass to downstream APIs.</description>
    </item>
    <item>
      <title>Multimodal Structured Generation: CVPR&#39;s 2nd MMFM Challenge Technical Report</title>
      <link>https://leloykun.github.io/papers/mmsg/</link>
      <pubDate>Mon, 17 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/papers/mmsg/</guid>
      <description>Multimodal Foundation Models (MMFMs) have shown remarkable performance on various computer vision and natural language processing tasks. However, their performance on particular tasks such as document understanding is still limited. They also require more compute, time, and engineering resources to finetune and deploy compared to traditional, unimodal models. In this report, we present Multimodal Structured Generation, a general framework which constrains the output logits of frozen MMFMs to force them to reason before responding with structured outputs that downstream APIs can parse and use. We provide a detailed account of our approach, including the technical details, theoretical discussions, and final evaluation results in the 2nd Multimodal Foundation Models Challenge hosted by the Computer Vision and Pattern Recognition (CVPR) conference. Our approach achieved the second highest score in the hidden test set for Phase 2 and third highest overall. This shows the method&amp;#39;s ability to generalize to unseen tasks. And that simple engineering can beat expensive &amp;amp; complicated modelling steps as we first discussed in our paper, Retrieval Augmented Structured Generation: Business Document Information Extraction as Tool Use.</description>
    </item>
    <item>
      <title>Flash Hyperbolic Attention Minimal [WIP]</title>
      <link>https://leloykun.github.io/personal-projects/flash-hyperbolic-attention-minimal/</link>
      <pubDate>Tue, 16 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/personal-projects/flash-hyperbolic-attention-minimal/</guid>
      <description>A minimal implementation of Flash Attention 1 &amp;amp; 2 in just ~350 lines of CUDA code. This is still a work-in-progress, but the ultimate goal is to implement the various variations of Hyperbolic Attention in CUDA.</description>
    </item>
    <item>
      <title>Retrieval Augmented Structured Generation: Business Document Information Extraction As Tool Use [Preprint - Accepted @ IEEE MIPR 2024]</title>
      <link>https://leloykun.github.io/papers/rasg/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/papers/rasg/</guid>
      <description>Business Document Information Extraction (BDIE) is the problem of transforming a blob of unstructured information (raw text, scanned documents, etc.) into a structured format that downstream systems can parse and use. It has two main tasks: Key-Information Extraction (KIE) and Line Items Recognition (LIR). In this paper, we argue that BDIE is best modeled as a Tool Use problem, where the tools are these downstream systems. We then present Retrieval Augmented Structured Generation (RASG), a novel general framework for BDIE that achieves state of the art (SOTA) results on both KIE and LIR tasks on BDIE benchmarks.
The contributions of this paper are threefold: (1) We show, with ablation benchmarks, that Large Language Models (LLMs) with RASG are already competitive with or surpasses current SOTA Large Multimodal Models (LMMs) without RASG on BDIE benchmarks. (2) We propose a new metric class for Line Items Recognition, General Line Items Recognition Metric (GLIRM), that is more aligned with practical BDIE use cases compared to existing metrics, such as ANLS*, DocILE, and GriTS. (3) We provide a heuristic algorithm for backcalculating bounding boxes of predicted line items and tables without the need for vision encoders. Finally, we claim that, while LMMs might sometimes offer marginal performance benefits, LLMs &#43; RASG is oftentimes superior given real-world applications and constraints of BDIE.</description>
    </item>
    <item>
      <title>The Human Mind May Be Universal</title>
      <link>https://leloykun.github.io/ponder/human-mind-universality/</link>
      <pubDate>Sun, 10 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/ponder/human-mind-universality/</guid>
      <description>Years of experience in building artificial minds led me to believe that these AIs may end up seeming more &amp;#39;human&amp;#39; than we currently imagine them to be.</description>
    </item>
    <item>
      <title>Llama.cpp</title>
      <link>https://leloykun.github.io/personal-projects/llama.cpp/</link>
      <pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/personal-projects/llama.cpp/</guid>
      <description>A C&#43;&#43; implementation of Meta&amp;#39;s Llama2 generative large-language model. I also optimized the original C implementation by Karpathy by adding parallelization on the multi-head attention layer.</description>
    </item>
    <item>
      <title>Expedock Assistant: ChatGPT Applied to Logistics Data</title>
      <link>https://leloykun.github.io/personal-projects/expedock-assistant/</link>
      <pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/personal-projects/expedock-assistant/</guid>
      <description>Expedock Assistant is a chatbot that allows you to ask questions about your shipments and get answers in real time. Itâ€™s like having a personal assistant that knows everything about your business, shipments and industry.</description>
    </item>
    <item>
      <title>Expedock AutoML</title>
      <link>https://leloykun.github.io/personal-projects/expedock-automl/</link>
      <pubDate>Mon, 25 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/personal-projects/expedock-automl/</guid>
      <description>Expedock&amp;#39;s AutoML Library -- fit a model, run batch inference, and get explanations in one line of code each.</description>
    </item>
    <item>
      <title>Vaccine Search as a Computational Problem</title>
      <link>https://leloykun.github.io/ponder/vaccine-search-as-comp-prob/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/ponder/vaccine-search-as-comp-prob/</guid>
      <description>A thought dump on mRNA vaccines and the future of computational biology</description>
    </item>
    <item>
      <title>Booking Demand Prediction for Grab SEA</title>
      <link>https://leloykun.github.io/personal-projects/grab-booking-demand-prediction/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/personal-projects/grab-booking-demand-prediction/</guid>
      <description>Booking demand prediction for Grab&amp;#39;s Southeast Asia operations. The project involves spatio-temporal forecasting, anomaly detection, and econometric modeling.</description>
    </item>
  </channel>
</rss>
