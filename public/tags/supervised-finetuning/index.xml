<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Supervised Finetuning on Franz Louis Cesista</title>
    <link>https://leloykun.github.io/tags/supervised-finetuning/</link>
    <description>Recent content in Supervised Finetuning on Franz Louis Cesista</description>
    <image>
      <title>Franz Louis Cesista</title>
      <url>https://leloykun.github.io/cover.png</url>
      <link>https://leloykun.github.io/cover.png</link>
    </image>
    <generator>Hugo -- 0.125.4</generator>
    <language>en</language>
    <lastBuildDate>Mon, 15 Apr 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://leloykun.github.io/tags/supervised-finetuning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Retrieval Augmented Structured Generation: Business Document Information Extraction As Tool Use [Preprint - Accepted @ IEEE MIPR 2024]</title>
      <link>https://leloykun.github.io/papers/rasg/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://leloykun.github.io/papers/rasg/</guid>
      <description>Business Document Information Extraction (BDIE) is the problem of transforming a blob of unstructured information (raw text, scanned documents, etc.) into a structured format that downstream systems can parse and use. It has two main tasks: Key-Information Extraction (KIE) and Line Items Recognition (LIR). In this paper, we argue that BDIE is best modeled as a Tool Use problem, where the tools are these downstream systems. We then present Retrieval Augmented Structured Generation (RASG), a novel general framework for BDIE that achieves state of the art (SOTA) results on both KIE and LIR tasks on BDIE benchmarks.
The contributions of this paper are threefold: (1) We show, with ablation benchmarks, that Large Language Models (LLMs) with RASG are already competitive with or surpasses current SOTA Large Multimodal Models (LMMs) without RASG on BDIE benchmarks. (2) We propose a new metric class for Line Items Recognition, General Line Items Recognition Metric (GLIRM), that is more aligned with practical BDIE use cases compared to existing metrics, such as ANLS*, DocILE, and GriTS. (3) We provide a heuristic algorithm for backcalculating bounding boxes of predicted line items and tables without the need for vision encoders. Finally, we claim that, while LMMs might sometimes offer marginal performance benefits, LLMs &#43; RASG is oftentimes superior given real-world applications and constraints of BDIE.</description>
    </item>
  </channel>
</rss>
