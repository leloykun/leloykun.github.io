<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Deep Learning Optimizers as Steepest Descent in Normed Spaces | Franz Louis Cesista</title>
<meta name="keywords" content="Machine Learning, Muon">
<meta name="description" content="Instead of asking, &#39;Which optimizer should I use?&#39; ask, &#39;In which space do my features live in?&#39;">
<meta name="author" content="Franz Louis Cesista">
<link rel="canonical" href="https://leloykun.github.io/ponder/steepest-descent-opt/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.e50e51e1b615f62676c32fb60e15e4b5e3a80ade29f3c6f9c953c528f576fb9f.css" integrity="sha256-5Q5R4bYV9iZ2wy&#43;2DhXkteOoCt4p88b5yVPFKPV2&#43;58=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://leloykun.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://leloykun.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://leloykun.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://leloykun.github.io/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://leloykun.github.io/ponder/steepest-descent-opt/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Deep Learning Optimizers as Steepest Descent in Normed Spaces" />
<meta property="og:description" content="Instead of asking, &#39;Which optimizer should I use?&#39; ask, &#39;In which space do my features live in?&#39;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://leloykun.github.io/ponder/steepest-descent-opt/" />
<meta property="og:image" content="https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro.png" /><meta property="article:section" content="ponder" />
<meta property="article:published_time" content="2024-10-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-10-20T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro.png" />
<meta name="twitter:title" content="Deep Learning Optimizers as Steepest Descent in Normed Spaces"/>
<meta name="twitter:description" content="Instead of asking, &#39;Which optimizer should I use?&#39; ask, &#39;In which space do my features live in?&#39;"/>
<meta name="twitter:site" content="@leloykun"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Ponder",
      "item": "https://leloykun.github.io/ponder/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Deep Learning Optimizers as Steepest Descent in Normed Spaces",
      "item": "https://leloykun.github.io/ponder/steepest-descent-opt/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Deep Learning Optimizers as Steepest Descent in Normed Spaces",
  "name": "Deep Learning Optimizers as Steepest Descent in Normed Spaces",
  "description": "Instead of asking, 'Which optimizer should I use?' ask, 'In which space do my features live in?'",
  "keywords": [
    "Machine Learning", "Muon"
  ],
  "articleBody": " Note: This was originally posted as a Twitter thread. I’ve reformatted it here for better readability.\nWhy do steepest descent in non-Euclidean spaces? Why does adaptive preconditioning work so well in practice? And, Why normalize everything ala nGPT? Ideally, when training a neural network, we want to bound the features, the weights, and their respective updates so that:\n[lower] the model actually “learns” stuff; and [upper] model training is stable These bounds then depend on the norms, but which norms?\nThe fun part is that the norms of the input and output features already induce the norm of the weights between them. We can also let the feature and feature updates have the same norm (likewise for the weights). And so, we only have to choose the norms for the features!\nNow, our datasets are usually Euclidean or locally Euclidean (see Manifold Hypothesis)\nWhat’s the norm induced by Euclidean input and output vector spaces? The Spectral Norm!\nSo even if we don’t want to do anything fancy, we’d still have to do steepest descent in non-Euclidean space because:\nThe induced norm for the weights (w/ Euclidean features) is non-Euclidean; and We’re optimizing the weights, not the features. The model inputs and outputs being Euclidean sounds reasonable, but why do the “hidden” features have to be Euclidean too?\nIf we vary the norms of these features, we also vary the induced norms of the weights and vice versa.\nAdaptive preconditioning then “searches” for the proper norms.\nThis also answers @mattecapu’s Q here\nShampoo \u0026 SOAP starts from Euclidean features and Spectral weights, then tunes the norms over time. SOAP does this tuning with momentum so it’s theoretically faster.\nreally cool to also optimize the p in the norm. do you have a conceptual idea of what that’s tuning? I guess intuitively as p-\u003eoo each dimension is getting ‘further away’ from each other..\nhttps://x.com/mattecapu/status/1847218617567301804\nA more cynical answer, from a mathematician to another, is that almost nobody in this field is actually doing proper linear algebra. Adaptive preconditioning allows us to start from really crappy configurations/parametrizations and get away scoff free.\nBut a more pro-ML answer would be that humans suck at predicting which inductive biases would work best when cooked into the models. E.g. why should the “hidden” features be in Euclidean space? Why not let the model learn the proper space(s) to work with?\nFinally, why is it a good idea to normalize everything everywhere?\nCuz it lets us have sane bounds \u0026 same norms on the features which means we can use the same optimizer for all the layers with minimal tuning!\nhttps://arxiv.org/abs/2410.01131\nHow to Cite @misc{cesista2024firstordernormedopt, author = {Franz Louis Cesista}, title = {Deep Learning Optimizers as Steepest Descent in Normed Spaces}, year = {2024}, url = {http://leloykun.github.io/ponder/steepest-descent-opt/}, } References Loshchilov, I., Hsieh, C., Sun, S., Ginsburg, B. (2024). nGPT: Normalized Transformer with Representation Learning on the Hypersphere. URL https://arxiv.org/abs/2410.01131 Yang, G., Simon, J., Bernstein, J. (2024). A Spectral Condition for Feature Learning. URL https://arxiv.org/abs/2310.17813 Bernstein, J., Newhouse, L. (2024). Old Optimizer, New Norm: An Anthology. URL https://arxiv.org/abs/2409.20325 ",
  "wordCount" : "510",
  "inLanguage": "en",
  "image":"https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro.png","datePublished": "2024-10-20T00:00:00Z",
  "dateModified": "2024-10-20T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Franz Louis Cesista"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://leloykun.github.io/ponder/steepest-descent-opt/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Franz Louis Cesista",
    "logo": {
      "@type": "ImageObject",
      "url": "https://leloykun.github.io/favicon.ico"
    }
  }
}
</script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-BWCGBRX8G1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BWCGBRX8G1');
</script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css"
  integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js"
  integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js"
  integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
        { left: "\\begin{equation}", right: "\\end{equation}", display: true },
        { left: "\\begin{equation*}", right: "\\end{equation*}", display: true },
        { left: "\\begin{align}", right: "\\end{align}", display: true },
        { left: "\\begin{align*}", right: "\\end{align*}", display: true },
        { left: "\\begin{alignat}", right: "\\end{alignat}", display: true },
        { left: "\\begin{gather}", right: "\\end{gather}", display: true },
        { left: "\\begin{CD}", right: "\\end{CD}", display: true },
      ],
      throwOnError: false,
      trust: (context) => ['\\htmlId', '\\href'].includes(context.command),
      macros: {
        "\\eqref": "\\href{###1}{(\\text{#1})}",
        "\\ref": "\\href{###1}{\\text{#1}}",
        "\\label": "\\htmlId{#1}{}"
      }
    });
  });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://leloykun.github.io/" accesskey="h" title="Franz Louis Cesista">
                <img src="https://leloykun.github.io/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Franz Louis Cesista</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://leloykun.github.io/cv.pdf" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/papers/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/personal-projects/" title="Personal Projects">
                    <span>Personal Projects</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/ponder/" title="Ponder (Posts)">
                    <span>Ponder (Posts)</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Deep Learning Optimizers as Steepest Descent in Normed Spaces
    </h1>
    <div class="post-meta"><span title='2024-10-20 00:00:00 +0000 UTC'>October 20, 2024</span>&nbsp;&middot;&nbsp;Franz Louis Cesista&nbsp;&middot;&nbsp;<a href="https://x.com/leloykun/status/1847919153589735705" rel="noopener noreferrer" target="_blank">Crossposted from X (formerly Twitter)</a>

</div>
  </header> 
<figure class="entry-cover">
            <img loading="eager"
                srcset='https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro_hu_d652b7ba8e8853c4.png 360w,https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro_hu_18c15e7af0a5f9a3.png 480w,https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro_hu_bbe4cd8365d2ab4e.png 720w,https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro_hu_26fc25fabac4a9a7.png 1080w,https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro_hu_a5ef42b6cd397397.png 1500w,https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro.png 2975w'
                src="https://leloykun.github.io/ponder/steepest-descent-opt/deep-learning-optimizers-intro.png"
                sizes="(min-width: 768px) 720px, 100vw"
                width="2975" height="2290"
                alt="Cover">
        
</figure><div class="toc">
    <details  open>
        <summary accesskey="c">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#how-to-cite">How to Cite</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><blockquote>
<p>Note: This was originally posted as a Twitter thread. I&rsquo;ve reformatted it here for better readability.</p></blockquote>
<ol>
<li>Why do steepest descent in non-Euclidean spaces?</li>
<li>Why does adaptive preconditioning work so well in practice? And,</li>
<li>Why normalize everything ala nGPT?</li>
</ol>
<hr>
<p>Ideally, when training a neural network, we want to bound the features, the weights, and their respective updates so that:</p>
<ol>
<li>[lower] the model actually &ldquo;learns&rdquo; stuff; and</li>
<li>[upper] model training is stable</li>
</ol>
<p>These bounds then depend on the norms, but which norms?</p>
<div align="center">
    <img src="dl-opt-bounds.png" style="width:70%; height:70%" />
</div>
<hr>
<p>The fun part is that the norms of the input and output features already induce the norm of the weights between them. We can also let the feature and feature updates have the same norm (likewise for the weights). And so, we only have to choose the norms for the features!</p>
<div align="center">
    <img src="dl-opt-induced-norms.png" style="width:70%; height:70%" />
</div>
<hr>
<p>Now, our datasets are usually Euclidean or locally Euclidean (see Manifold Hypothesis)</p>
<p>What&rsquo;s the norm induced by Euclidean input and output vector spaces? The Spectral Norm!</p>
<div align="center">
    <img src="dl-opt-norms.png" style="width:80%; height:80%" />
</div>
<hr>
<p>So even if we don&rsquo;t want to do anything fancy, we&rsquo;d still have to do steepest descent in non-Euclidean space because:</p>
<ol>
<li>The induced norm for the weights (w/ Euclidean features) is non-Euclidean; and</li>
<li>We&rsquo;re optimizing the weights, not the features.</li>
</ol>
<hr>
<p>The model inputs and outputs being Euclidean sounds reasonable, but why do the &ldquo;hidden&rdquo; features have to be Euclidean too?</p>
<p>If we vary the norms of these features, we also vary the induced norms of the weights and vice versa.</p>
<p>Adaptive preconditioning then &ldquo;searches&rdquo; for the proper norms.</p>
<div align="center">
    <img src="dl-opt-adaptive.png" style="width:90%; height:90%" />
</div>
<hr>
<p>This also answers <a href="https://x.com/mattecapu" target="_blank">@mattecapu</a>&rsquo;s Q here</p>
<p>Shampoo &amp; SOAP starts from Euclidean features and Spectral weights, then tunes the norms over time. SOAP does this tuning with momentum so it&rsquo;s theoretically faster.</p>
<blockquote>
<p>really cool to also optimize the p in the norm. do you have a conceptual idea of what that&rsquo;s tuning? I guess intuitively as p-&gt;oo each dimension is getting &lsquo;further away&rsquo; from each other..</p></blockquote>
<p><a href="https://x.com/mattecapu/status/1847218617567301804" target="_blank">https://x.com/mattecapu/status/1847218617567301804</a></p>
<p>A more cynical answer, from a mathematician to another, is that almost nobody in this field is actually doing proper linear algebra. Adaptive preconditioning allows us to start from really crappy configurations/parametrizations and get away scoff free.</p>
<p>But a more pro-ML answer would be that humans suck at predicting which inductive biases would work best when cooked into the models. E.g. why should the &ldquo;hidden&rdquo; features be in Euclidean space? Why not let the model learn the proper space(s) to work with?</p>
<hr>
<p>Finally, why is it a good idea to normalize everything everywhere?</p>
<p>Cuz it lets us have sane bounds &amp; same norms on the features which means we can use the same optimizer for all the layers with minimal tuning!</p>
<p><a href="https://arxiv.org/abs/2410.01131" target="_blank">https://arxiv.org/abs/2410.01131</a></p>
<h2 id="how-to-cite">How to Cite<a hidden class="anchor" aria-hidden="true" href="#how-to-cite">#</a></h2>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bibtex" data-lang="bibtex"><span style="display:flex;"><span><span style="color:#0a0;text-decoration:underline">@misc</span>{cesista2024firstordernormedopt,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">author</span> = <span style="color:#a50">{Franz Louis Cesista}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">title</span> = <span style="color:#a50">{Deep Learning Optimizers as Steepest Descent in Normed Spaces}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">year</span> = <span style="color:#a50">{2024}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">url</span> = <span style="color:#a50">{http://leloykun.github.io/ponder/steepest-descent-opt/}</span>,
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<ul>
<li>Loshchilov, I., Hsieh, C., Sun, S., Ginsburg, B. (2024). nGPT: Normalized Transformer with Representation Learning on the Hypersphere. URL <a href="https://arxiv.org/abs/2410.01131" target="_blank">https://arxiv.org/abs/2410.01131</a></li>
<li>Yang, G., Simon, J., Bernstein, J. (2024). A Spectral Condition for Feature Learning. URL <a href="https://arxiv.org/abs/2310.17813" target="_blank">https://arxiv.org/abs/2310.17813</a></li>
<li>Bernstein, J., Newhouse, L. (2024). Old Optimizer, New Norm: An Anthology. URL <a href="https://arxiv.org/abs/2409.20325" target="_blank">https://arxiv.org/abs/2409.20325</a></li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://leloykun.github.io/tags/machine-learning/">Machine Learning</a></li>
      <li><a href="https://leloykun.github.io/tags/muon/">Muon</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Learning Optimizers as Steepest Descent in Normed Spaces on x"
            href="https://x.com/intent/tweet/?text=Deep%20Learning%20Optimizers%20as%20Steepest%20Descent%20in%20Normed%20Spaces&amp;url=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-opt%2f&amp;hashtags=MachineLearning%2cMuon">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Learning Optimizers as Steepest Descent in Normed Spaces on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-opt%2f&amp;title=Deep%20Learning%20Optimizers%20as%20Steepest%20Descent%20in%20Normed%20Spaces&amp;summary=Deep%20Learning%20Optimizers%20as%20Steepest%20Descent%20in%20Normed%20Spaces&amp;source=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-opt%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Learning Optimizers as Steepest Descent in Normed Spaces on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-opt%2f&title=Deep%20Learning%20Optimizers%20as%20Steepest%20Descent%20in%20Normed%20Spaces">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Learning Optimizers as Steepest Descent in Normed Spaces on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-opt%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Learning Optimizers as Steepest Descent in Normed Spaces on whatsapp"
            href="https://api.whatsapp.com/send?text=Deep%20Learning%20Optimizers%20as%20Steepest%20Descent%20in%20Normed%20Spaces%20-%20https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-opt%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Learning Optimizers as Steepest Descent in Normed Spaces on telegram"
            href="https://telegram.me/share/url?text=Deep%20Learning%20Optimizers%20as%20Steepest%20Descent%20in%20Normed%20Spaces&amp;url=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-opt%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Learning Optimizers as Steepest Descent in Normed Spaces on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Deep%20Learning%20Optimizers%20as%20Steepest%20Descent%20in%20Normed%20Spaces&u=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-opt%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://leloykun.github.io/">Franz Louis Cesista</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
