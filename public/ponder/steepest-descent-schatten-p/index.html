<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Steepest Descent Under Schatten-p Norms | Franz Louis Cesista</title>
<meta name="keywords" content="Machine Learning, Muon">
<meta name="description" content="Why Muon still work despite not perfectly semi-orthogonalizing the gradients.">
<meta name="author" content="Franz Louis Cesista">
<link rel="canonical" href="https://leloykun.github.io/ponder/steepest-descent-schatten-p/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.e50e51e1b615f62676c32fb60e15e4b5e3a80ade29f3c6f9c953c528f576fb9f.css" integrity="sha256-5Q5R4bYV9iZ2wy&#43;2DhXkteOoCt4p88b5yVPFKPV2&#43;58=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://leloykun.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://leloykun.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://leloykun.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://leloykun.github.io/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://leloykun.github.io/ponder/steepest-descent-schatten-p/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Steepest Descent Under Schatten-p Norms" />
<meta property="og:description" content="Why Muon still work despite not perfectly semi-orthogonalizing the gradients." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://leloykun.github.io/ponder/steepest-descent-schatten-p/" /><meta property="article:section" content="ponder" />
<meta property="article:published_time" content="2025-02-27T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-02-27T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Steepest Descent Under Schatten-p Norms"/>
<meta name="twitter:description" content="Why Muon still work despite not perfectly semi-orthogonalizing the gradients."/>
<meta name="twitter:site" content="@leloykun"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Ponder",
      "item": "https://leloykun.github.io/ponder/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Steepest Descent Under Schatten-p Norms",
      "item": "https://leloykun.github.io/ponder/steepest-descent-schatten-p/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Steepest Descent Under Schatten-p Norms",
  "name": "Steepest Descent Under Schatten-p Norms",
  "description": "Why Muon still work despite not perfectly semi-orthogonalizing the gradients.",
  "keywords": [
    "Machine Learning", "Muon"
  ],
  "articleBody": "Prologue When training a neural network, our goal is to find parameters $\\hat{W} = \\{W_l\\}_{1 \\leq l \\leq L}$ that minimize a loss function $L(\\hat{W})$ with respect to some training data. This loss function is typically non-convex and/or intractable to compute exactly. Thus, we resort to iterative optimization algorithms to find a decent local minimum instead.\nAnd every minute choice we make on how we approximate $L$ leads to a different optimization algorithm. To illustrate this simply, let’s focus on one of the parameters $W_l$ and let’s take the Taylor expansion of $L$ around $W_l$: $$L(W_l + \\Delta W_l) = L(W_l) + \\langle\\nabla L(W_l), \\Delta W_l\\rangle_F + \\frac{1}{2} \\langle\\Delta W_l, H(W_l) \\Delta W_l\\rangle_F + \\ldots,$$ where $\\nabla L(W_l)$ is the gradient of $L$ at $W_l$, $H(W_l)$ is the Hessian of $L$ at $W_l$, and $\\langle\\cdot, \\cdot\\rangle_F$ is the Frobenius inner product: $$\\langle A, B\\rangle_F = \\text{tr}(A^T B) = \\sum_{i,j} A_{ij}B_{ij}.$$\nOur goal at each iteration then is to find $\\Delta W_l$ that minimizes $L(W_l + \\Delta W_l)$. I.e.: $$\\Delta W_l^* = \\arg\\min_{\\Delta W_l} L(W_l + \\Delta W_l)$$\nAnd from here, we have three choies on how to approximate $L$ (and consequently $\\Delta W_l^*$):\nSecond-order methods. Drop the third-order and subsequent terms in the Taylor expansion: $$\\Delta W_l^* = \\arg\\min_{\\Delta W_l} \\{\\langle\\nabla L(W_l), \\Delta W_l\\rangle_F + \\frac{1}{2} \\langle\\Delta W_l, H(W_l) \\Delta W_l\\rangle_F\\}$$ Then, using Newton’s method, we get: $$\\Delta W_l^* = -H(W_l)^{-1} \\nabla L(W_l)$$ However, computing the Hessian, let alone inverting it, is computationally expensive. Thus, second-order optimizers like Shampoo and CASPR resort to adding more assumptions to the structure of the Hessian to get the job done. We will discuss more on this in a future post.\nFirst-order with a soft norm penalty. Here, we approximate the second-order and subsequent terms in the Taylor expansion with a (squared-) norm penalty: $$\\Delta W_l^* = \\arg\\min_{\\Delta W_l} \\{\\langle\\nabla L(W_l), \\Delta W_l\\rangle_F + \\frac{\\lambda}{2} ||\\Delta W_l||^2\\},$$ for some norm $||\\cdot||$ and some sharpness parameter $\\lambda$ chosen a priori. This leads to the work of Bernstein \u0026 Newhouse (2024) on Steepest Descent Under Operator Norms where they show that the optimal $\\Delta W_l^*$ is: $$\\Delta W_l^* = -\\frac{||\\nabla L(W_l)||^{\\dagger}}{\\lambda}\\text{dualizer}_{||\\cdot||}(\\nabla L(W_l)),$$ where $||\\cdot||^{\\dagger}$ is the dual norm of $||\\cdot||$ and $$\\text{dualizer}_{||\\cdot||}(X) = \\arg\\max_{||T|| = 1}\\langle X, T \\rangle_F.$$\nFirst-order with a hard norm constraint. This is similar to the previous choice but we require that $\\Delta W_l$ be of some fixed “length” $r$ with respect to the norm $||\\cdot||$: $$\\Delta W_l^* = \\arg\\min_{\\Delta W_l} \\langle\\nabla L(W_l), \\Delta W_l\\rangle_F \\quad \\text{s.t.} \\quad ||\\Delta W_l|| = r.$$ This leads to the work of Pethick et al. (2025) on Linear Minimization Oracle (LMO) over a norm ball.\nNow, notice that for $r = 1$, the only difference between the second and third choices is actually the scaling factor or the “learning rate”, the schedule of which we can tune separately. Either way, the crucial part is how we choose the norm $||\\cdot||$–if we pick a different norm, we get a different class of optimizers.\nSteepest Descent Under Operator Norms Previous work by Bernstein \u0026 Newhouse (2024) and Pethick et al. (2025) have already worked out the dualizers for different operator norms and how they give rise to different optimizers.\nFrobenius Norm $||\\cdot||_F$: The dual norm of the Frobenius norm is the Frobenius norm itself. And its dualizer is fairly simple: $$ \\begin{align*} ||\\nabla L(W_l)||_F^{\\dagger} \u0026= ||\\nabla L(W_l)||_F\\\\ \\text{dualizer}_{||\\cdot||_F}(\\nabla L(W_l)) \u0026= \\frac{\\nabla L(W_l)}{||\\nabla L(W_l)||_F} \\end{align*} $$ Thus, the update rule for steepest descent under the Frobenius norm is: $$ \\begin{align*} \\Delta W_l^* \u0026= -\\frac{||\\nabla L(W_l)||_F}{\\lambda} \\frac{\\nabla L(W_l)}{||\\nabla L(W_l)||_F}\\\\ \\Delta W_l^* \u0026= -\\frac{1}{\\lambda} \\nabla L(W_l) \\end{align*} $$ which is just the update rule for Stochastic Gradient Descent (SGD).\nMax-of-Max Norm $||\\cdot||_{1 \\to \\infty}$: A unit-length matrix under this norm is a matrix where all entries are $\\pm 1$. And we can show that the unit-length matrix $T$ that maximizes the Frobenius inner product with the gradient $\\nabla L(W_l)$ is the matrix whose entries are the signs of the entries of $\\nabla L(W_l)$: $$\\text{dualizer}_{||\\cdot||_{1 \\to \\infty}}(\\nabla L(W_l)) = \\text{sign}(\\nabla L(W_l))$$ Thus, the update rule for steepest descent under the max-of-max norm is: $$ \\begin{align*} \\Delta W_l^* \u0026= -\\frac{||\\nabla L(W_l)||_{1 \\to \\infty}^\\dagger}{\\lambda} \\text{sign}(\\nabla L(W_l))\\\\ \\Delta W_l^* \u0026= -\\frac{1}{\\hat{\\lambda}} \\frac{\\nabla L(W_l)}{\\sqrt{\\nabla L(W_l) \\odot \\nabla L(W_l)}} \\end{align*} $$ where $\\hat{\\lambda} = \\frac{\\lambda}{||\\nabla L(W_l)||_{1 \\to \\infty}^\\dagger}$ and $\\odot$ is the element-wise (Hadamard) product. Note that this is the update rule for Adam without accumulation.\nSpectral Norm $||\\cdot||_{2 \\to 2}$: A unit-length matrix under this norm is a matrix whose singular values are all 1. And we can show that the unit-length matrix $T$ that maximizes the Frobenius inner product with the gradient $\\nabla L(W_l)$ is the matrix whose singular vectors are also the singular vectors of $\\nabla L(W_l)$. We will prove this more rigorously in the next section. But for now, the dualizer for the spectral norm is: $$\\text{dualizer}_{||\\cdot||_{2 \\to 2}}(\\nabla L(W_l)) = UV^T,$$ where $\\nabla L(W_l) = U\\Sigma V^T$ is the singular value decomposition of $\\nabla L(W_l)$. Thus, the update rule for steepest descent under the spectral norm is: $$ \\begin{align*} \\Delta W_l^* \u0026= -\\frac{||\\nabla L(W_l)||_{2 \\to 2}^{\\dagger}}{\\lambda} UV^T\\\\ \\Delta W_l^* \u0026= -\\frac{1}{\\hat{\\lambda}} UV^T \\end{align*} $$ where $\\hat{\\lambda} = \\frac{\\lambda}{||\\nabla L(W_l)||^{\\dagger}_{2 \\to 2}}$ which is just the update rule for Muon.\nSteepest Descent Under Schatten-$p$ Norms We can generalize the above to the Schatten-$p$ norms.\nSchatten-$p$ Norms Definition 1: Schatten-$p$ Norm. The Schatten-$p$ norm of a matrix $A$ is defined as: $$||A||_p = \\left(\\sum_{i=1}^{\\min(m, n)} |\\sigma_i(A)|^p\\right)^{1/p},$$ where $\\sigma_i(A)$ are the singular values of $A$.\nIn a sense, you can think of the Schatten-$p$ norm of $A$ as the $p$-norm of the singular values of $A.$\nExamples:\n$p = 1$: The Nuclear norm, $||A||_{S_1} = \\sum_{i=1}^{\\min(m,n)} |\\sigma_i(A)|$ $p = 2$: The Frobenius norm, $||A||_{S_2} = \\left(\\sum_{i=1}^{\\min(m,n)} |\\sigma_i(A)|^2\\right)^{\\frac{1}{2}} = ||A||_F$ $p = \\infty$: The Spectral norm, $||A||_{S_{\\infty}} = \\max_{i} \\sigma_i(A) = ||A||_{2 \\to 2}$ $(2)$ may be non-obvious to some, but here’s a short proof: $$ \\begin{align*} ||A||_F \u0026= \\sqrt{\\sum_{ij} A_{ij}^2} = \\sqrt{tr(A^TA)} = \\sqrt{tr((U\\Sigma V^T)^T(U\\Sigma V^T))}\\\\ \u0026= \\sqrt{tr(V \\Sigma^2 V^T)} = \\left(\\sum_i \\sigma_i(A)^2\\right)^{\\frac{1}{2}} = ||A||_{S_2} \\end{align*} $$\nvon Neumann’s Trace Inequality And to find the dualizers for the Schatten-$p$ norms, we need the following inequality:\nTheorem (von Neumann’s Trace Inequality). Let $A$ and $B$ be two matrices. Then, the following inequality holds: $$\\text{tr}(A^TB) \\leq \\sum_{i=1}^{\\min(m,n)} \\sigma_i(A) \\sigma_i(B),$$ where $\\sigma_i(A)$ are the singular values of $A$. And equality holds if and only if $A$ and $B$ share singular vectors.\nSteepest descent under Schatten-$p$ Norms Here, we derive the dualizer for an arbitrary Schatten-$p$ norm.\nProposition 2. The dualizer for the Schatten-$p$ norm is: $$\\text{dualizer}_{||\\cdot||_{S_p}}(X) = U \\frac{\\text{diag}\\left(\\sigma_1(X)^{q-1}, \\ldots, \\sigma_{\\min(m,n)}(X)^{q-1}\\right)}{||X||_{S_q}^{q-1}} V^T$$ where $X = U\\Sigma V^T$ is the singular value decomposition of $X$ and $\\frac{1}{p} + \\frac{1}{q} = 1$.\nProof: For a given $X$, let $T^*$ be: $$ \\begin{align*} T^* \u0026= \\text{dualizer}_{||\\cdot||_{S_p}}(X)\\\\ T^* \u0026= \\arg\\max_{||T||_{S_p} = 1} \\langle X, T \\rangle_F\\\\ T^* \u0026= \\arg\\max_{||T||_{S_p} = 1} \\text{tr}(X^T T) \\end{align*} $$ Then, from von Neumann’s Trace Inequality, we know that $T^*$ must share singular vectors with $X$ and that: $$T^* = \\arg\\max_{||T||_{S_p} = 1} \\sum_{i=1} \\sigma_i(X) \\sigma_i(T)$$ Thus, our optimization problem reduces to $$\\max_{\\{\\sigma_i(T)\\}} \\sum_i \\sigma_i(X) \\sigma_i(T) \\quad\\text{s.t.}\\quad \\sum \\sigma_i(T)^p = 1$$ which we can solve via Lagrange multipliers. See appendix for the full proof. For now, the solution is: $$\\sigma_i(T) = \\frac{\\sigma_i(X)^{q-1}}{||X||_{S_q}^{q-1}}$$ Hence, $$T^* = \\text{dualizer}_{||\\cdot||_{S_p}}(X) = U \\frac{\\text{diag}\\left(\\sigma_1(X)^{q-1}, \\ldots, \\sigma_{\\min(m,n)}(X)^{q-1}\\right)}{||X||_{S_q}^{q-1}} V^T\\quad\\blacksquare$$\nThe proof that the dual norm of the Schatten-$p$ norm is the Schatten-$q$ norm where $\\frac{1}{p} + \\frac{1}{q} = 1$ actually follows directly from here:\nCorollary 3. The dual norm of the Schatten-$p$ norm is the Schatten-$q$ norm where $\\frac{1}{p} + \\frac{1}{q} = 1$.\nProof: For a given $X$, we want to show that $$||X||_{S_p}^{\\dagger} = ||X||_{S_q}$$ From the definition of the dual norm, we have: $$ \\begin{align*} ||X||_{S_p}^{\\dagger} \u0026= \\sup_{||T||_{S_p} \\leq 1} \\langle X, T \\rangle_F\\\\ ||X||_{S_p}^{\\dagger} \u0026= \\sup_{||T||_{S_p} \\leq 1} \\text{tr}(X^T T) \\end{align*} $$ Following Proposition 2, we know that we can achieve the supremum by choosing $T = \\text{dualizer}_{||\\cdot||_{S_p}}(X)$. Thus, $$ \\begin{align*} ||X||_{S_p}^{\\dagger} \u0026= \\text{tr}\\left(X^T U \\frac{\\text{diag}\\left(\\sigma_1(X)^{q-1}, \\ldots, \\sigma_{\\min(m,n)}(X)^{q-1}\\right)}{||X||_{S_q}^{q-1}} V^T\\right)\\\\ \u0026= \\sum_i \\sigma_i(X) \\frac{\\sigma_i(X)^{q-1}}{||X||_{S_q}^{q-1}}\\\\ \u0026= \\frac{1}{||X||_{S_q}^{q-1}} \\sum_i \\sigma_i(X)^q\\\\ \u0026= \\frac{||X||_{S_q}^q}{||X||_{S_q}^{q-1}}\\\\ ||X||_{S_p}^{\\dagger} \u0026= ||X||_{S_q}\\quad\\blacksquare \\end{align*} $$\nFinally,\nTheorem 4. The update rule for steepest descent under the Schatten-$p$ norm is: $$\\Delta W_l^* = -\\frac{1}{\\hat{\\lambda}} U \\frac{\\text{diag}\\left(\\sigma_1(\\nabla L(W_l))^{q-1}, \\ldots, \\sigma_{\\min(m,n)}(\\nabla L(W_l))^{q-1}\\right)}{||\\nabla L(W_l)||_{S_q}^{q-1}} V^T$$ where $\\hat{\\lambda} = \\frac{\\lambda}{||\\nabla L(W_l)||_{S_q}}$, $\\nabla L(W_l) = U\\Sigma V^T$ is the singular value decomposition of $\\nabla L(W_l)$, and $\\frac{1}{p} + \\frac{1}{q} = 1$.\nThe proof follows directly from Proposition 2 and Corollary 3.\nSanity Checks Our results should match prior results for $p = 2, \\infty$:\nFor $p = 2$, the Frobenius norm: $q = 2$ and $||\\cdot||_{S_2}^\\dagger = ||\\cdot||_{S_2} = ||\\cdot||_F$. Thus, $$ \\begin{align*} \\text{dualizer}_{||\\cdot||_{S_2}}(X) \u0026= U \\frac{\\text{diag}\\left(\\sigma_1(X)^{2-1}, \\ldots, \\sigma_{\\min(m,n)}(X)^{2-1}\\right)}{||X||_{S_2}^{2-1}} V^T\\\\ \\text{dualizer}_{||\\cdot||_F}(X) \u0026= \\frac{X}{||X||_F} \\end{align*} $$ Thus, $$ \\begin{align*} \\Delta W_l^* \u0026= -\\frac{||\\nabla L(W_l)||_F}{\\lambda} \\frac{\\nabla L(W_l)}{||\\nabla L(W_l)||_F}\\\\ \\Delta W_l^* \u0026= -\\frac{1}{\\lambda} \\nabla L(W_l) \\end{align*} $$\nFor $p = \\infty$, the Spectral norm: $q = 1$ and $||\\cdot||_{S_\\infty}^\\dagger = ||\\cdot||_{S_1}$. Thus, $$ \\begin{align*} \\text{dualizer}_{||\\cdot||_{S_\\infty}}(X) \u0026= U \\frac{\\text{diag}\\left(\\sigma_1(X)^{1-1}, \\ldots, \\sigma_{\\min(m,n)}(X)^{1-1}\\right)}{||X||_{S_1}^{1-1}} V^T\\\\ \\text{dualizer}_{||\\cdot||_{2 \\to 2}}(X) \u0026= UV^T \\end{align*} $$ Thus, $$ \\begin{align*} \\Delta W_l^* \u0026= -\\frac{||\\nabla L(W_l)||_{S_1}}{\\lambda} UV^T\\\\ \\Delta W_l^* \u0026= -\\frac{1}{\\hat{\\lambda}} UV^T \\end{align*} $$ where $\\hat{\\lambda} = \\frac{\\lambda}{||\\nabla L(W_l)||_{S_1}}$.\nBoth of which matches prior results. And as a fun exercise, try to prove that the dualizer for the Schatten-$1$ norm, or the Nuclear norm, results in a rank-$k$ matrix where $k$ is the multiplicity of the largest singular value.\nWhat Does the Dualizer Actually Do? We observe that steepest descent under the Schatten-$p$ norm very quickly starts to “look like” steepest descent under the Spectral norm as $p$ approaches $\\infty$. This is probably why optimizers that merely approximately semi-orthogonalize the gradients like Sketching and Muon work so well in practice despite resulting in (relatively) high-variance of singular values post-dualization.\nTo support this, we show that the (1) variance of singular values, and the (2) relative size, and (3) stable rank of the gradients post-dualization under the Schatten-$p$ norm converge to those of the Spectral norm very quickly as $p$ approaches $\\infty$. And in fact, at $p = 32$, the results are already very close to those of the Spectral norm.\nOn the variance of singular values Proposition 5. The variance of the singular values post-dualization under the Schatten-$p$ Norm converges quadratically to $0$ as $p$ approaches $\\infty$.\nProof: Let $t_i$ be the $i$-th singular value post-dualization. From Proposition 2 earlier, we have $$ \\begin{align*} t_i \u0026= \\left(\\frac{\\sigma_i(\\nabla L(W_l))}{||\\nabla L(W_l)||_{S_q}}\\right)^{q-1}\\\\ t_i \u0026= \\exp\\left((q-1)\\ln\\frac{\\sigma_i(\\nabla L(W_l))}{||\\nabla L(W_l)||_{S_q}}\\right)\\\\ t_i \u0026\\approx 1 + (q-1)\\ln\\frac{\\sigma_i(\\nabla L(W_l))}{||\\nabla L(W_l)||_{S_q}} \\end{align*} $$ where the last line follows from first-order Taylor approximation of $t_i$. Thus, the mean and variance are: $$ \\begin{align*} \\mathbb{E}[t_i] \u0026\\approx 1 + (q-1)\\mathbb{E}\\left[\\ln\\frac{\\sigma_i(\\nabla L(W_l))}{||\\nabla L(W_l)||_{S_q}}\\right]\\\\ \\mathbb{E}[t_i] \u0026\\approx 1 + (q-1)\\ln\\frac{\\mathbb{E}[\\sigma_i(\\nabla L(W_l))]}{||\\nabla L(W_l)||_{S_q}}\\\\ t_i - \\mathbb{E}[t_i] \u0026\\approx (q-1)\\ln\\left[\\sigma_i(\\nabla L(W_l)) - \\mathbb{E}[\\sigma_i(\\nabla L(W_l))]\\right]\\\\ Var[t_i] \u0026\\approx (q-1)^2\\mathbb{E}\\left[\\ln^2\\left[\\sigma_i(\\nabla L(W_l)) - \\mathbb{E}[\\sigma_i(\\nabla L(W_l))]\\right]\\right]\\\\ Var[t_i] \u0026\\approx \\frac{1}{(p-1)^2}\\mathbb{E}\\left[\\ln^2\\left[\\sigma_i(\\nabla L(W_l)) - \\mathbb{E}[\\sigma_i(\\nabla L(W_l))]\\right]\\right] \\end{align*} $$ Hence, the variance of the singular values post-dualization converges quadratically to $0$ as $p$ approaches $\\infty$.\nEmpirically, we can see this in the following plot. And at $p = 32$, the variance of the resulting singular values is already very close to $0$. On the relative size and stable rank of gradients Definition 6: Relative Size of a Gradient. Given a norm $||\\cdot||$ chosen a priori, the relative size of a gradient-update $\\Delta W$ relative to the parameter matrix $W$ is defined as: $$\\text{relsize}(\\Delta W) = \\frac{||\\Delta W||}{||W||}$$\nDefinition 7: Stable Rank. The stable rank of a matrix $A$ is defined as $$srank(A) = \\frac{||A||_F^2}{||A||_{2 \\to 2}^2}$$\nAs we can see in the following plot, the raw gradients have very low-stable rank. But the stable rank of the gradients post-dualization under the Schatten-$p$ norm converges very quickly to that of the Spectral norm as $p$ approaches $\\infty$.\nOne can interpret this as, for some large enough $p$, the dualized gradient is already very close to being “maximal” in a sense. And increasing $p$ further would only offer rapidly diminishing returns.\nFaster feature learning Why do we want ‘maximal’ updates? I’d love to dive deeper into this in a future post. But for now, I’ll leave you with these:\nWeight Erasure. Because the raw gradients are naturally “small” or have low stable rank, models trained with SGD, Adam, or similar optimizers tend to get ‘stuck’ within a small region of the parameter space around the initialization (Lee et al., 2020; Jesus et al., 2021). On the other hand, optimizers like Muon that ramp up the stable rank of the gradients can quickly ’escape’ the init region and explore the parameter space more effectively. If you want to learn more about this, check out Bernstein’s blog post on weight erasure (2024). Faster Feature Learning. Another reason we want ‘maximal’ updates is that it allows the model to learn features faster. If our updates are too small, they would vanish at larger model widths. E.g., it’s going to take you forever to learn a diverse features set on a 4096-wide model if your updates are merely rank-1. Ideally, our updates should “grow” with the model width. And, in a sense, this is what optimizers like Muon do. That’s it for now. Until next time!\nHow to Cite @misc{cesista2025schattenp, author = {Franz Louis Cesista}, title = {Steepest Descent Under Schatten-p Norms}, year = {2025}, url = {http://leloykun.github.io/ponder/steepest-descent-schatten-p/}, } References Jeremy Bernstein and Laker Newhouse. “Old optimizer, new norm: An anthology.” arXiv preprint arXiv:2409.20325 (2024). Jeremy Bernstein (2024). “Weight erasure.” Available at: https://docs.modula.systems/examples/weight-erasure/ Keller Jordan, Jeremy Bernstein, Brendan Rappazzo, @fernbear.bsky.social, Boza Vlado, Jiacheng You, Franz Cesista, Braden Koszarsky, and @Grad62304977. modded-nanogpt: Speedrunning the NanoGPT baseline. 2024. Available at: https://github.com/KellerJordan/modded-nanogpt. Keller Jordan, Yuchen Jin, Vlado Boza, Jiacheng You, Franz Cesista, Laker Newhouse, and Jeremy Bernstein (2024). Muon: An optimizer for hidden layers in neural networks. Available at: https://kellerjordan.github.io/posts/muon/. Vineet Gupta, Tomer Koren, Yoram Singer (2018). Shampoo: Preconditioned Stochastic Tensor Optimization. URL https://arxiv.org/abs/1802.09568 Rohan Anil et al. “Scalable second order optimization for deep learning.” arXiv preprint arXiv:2002.09018 (2020). Surya, S., Duvvuri, Devvrit, F., Anil, R., Hsieh, C., \u0026 Dhillon, I.S. (2024). Combining Axes Preconditioners through Kronecker Approximation for Deep Learning. International Conference on Learning Representations. Thomas Pethick, Wanyun Xie, Kimon Antonakopoulos, Zhenyu Zhu, Antonio Silveti-Falls, Volkan Cevher (2025). Training Deep Learning Models with Norm-Constrained LMOs. Available at: https://arxiv.org/abs/2502.07529. David E Carlson, Edo Collins, Ya-Ping Hsieh, Lawrence Carin, Volkan Cevher (2015). Preconditioned Spectral Descent for Deep Learning. Advances in Neural Information Processing Systems 28 (NIPS 2015) Lee, Jaehoon, et al. “Wide Neural Networks of Any Depth Evolve as Linear Models under Gradient Descent.” Journal of Statistical Mechanics: Theory and Experiment, vol. 2020, no. 12, Dec. 2020, p. 124002. Crossref, https://doi.org/10.1088/1742-5468/abc62b. Jesus, Ricardo J., et al. “Effect of Initial Configuration of Weights on Training and Function of Artificial Neural Networks.” Mathematics, vol. 9, no. 18, Sept. 2021, p. 2246. Crossref, https://doi.org/10.3390/math9182246. Greg Yang and James B. Simon and Jeremy Bernstein (2024). A Spectral Condition for Feature Learning. Available at: https://arxiv.org/abs/2310.17813. ",
  "wordCount" : "2471",
  "inLanguage": "en",
  "datePublished": "2025-02-27T00:00:00Z",
  "dateModified": "2025-02-27T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Franz Louis Cesista"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://leloykun.github.io/ponder/steepest-descent-schatten-p/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Franz Louis Cesista",
    "logo": {
      "@type": "ImageObject",
      "url": "https://leloykun.github.io/favicon.ico"
    }
  }
}
</script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-BWCGBRX8G1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BWCGBRX8G1');
</script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css"
  integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js"
  integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js"
  integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
        { left: "\\begin{equation}", right: "\\end{equation}", display: true },
        { left: "\\begin{equation*}", right: "\\end{equation*}", display: true },
        { left: "\\begin{align}", right: "\\end{align}", display: true },
        { left: "\\begin{align*}", right: "\\end{align*}", display: true },
        { left: "\\begin{alignat}", right: "\\end{alignat}", display: true },
        { left: "\\begin{gather}", right: "\\end{gather}", display: true },
        { left: "\\begin{CD}", right: "\\end{CD}", display: true },
      ],
      throwOnError: false,
      trust: (context) => ['\\htmlId', '\\href'].includes(context.command),
      macros: {
        "\\eqref": "\\href{###1}{(\\text{#1})}",
        "\\ref": "\\href{###1}{\\text{#1}}",
        "\\label": "\\htmlId{#1}{}"
      }
    });
  });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://leloykun.github.io/" accesskey="h" title="Franz Louis Cesista">
                <img src="https://leloykun.github.io/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Franz Louis Cesista</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://leloykun.github.io/cv.pdf" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/papers/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/personal-projects/" title="Personal Projects">
                    <span>Personal Projects</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/ponder/" title="Ponder (Posts)">
                    <span>Ponder (Posts)</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Steepest Descent Under Schatten-p Norms
    </h1>
    <div class="post-meta"><span title='2025-02-27 00:00:00 +0000 UTC'>February 27, 2025</span>&nbsp;&middot;&nbsp;Franz Louis Cesista

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#prologue">Prologue</a></li>
    <li><a href="#steepest-descent-under-operator-norms">Steepest Descent Under Operator Norms</a></li>
    <li><a href="#steepest-descent-under-schatten-p-norms">Steepest Descent Under Schatten-$p$ Norms</a>
      <ul>
        <li><a href="#schatten-p-norms">Schatten-$p$ Norms</a></li>
        <li><a href="#von-neumanns-trace-inequality">von Neumann&rsquo;s Trace Inequality</a></li>
        <li><a href="#steepest-descent-under-schatten-p-norms-1">Steepest descent under Schatten-$p$ Norms</a></li>
        <li><a href="#sanity-checks">Sanity Checks</a></li>
      </ul>
    </li>
    <li><a href="#what-does-the-dualizer-actually-do">What Does the Dualizer Actually Do?</a>
      <ul>
        <li><a href="#on-the-variance-of-singular-values">On the variance of singular values</a></li>
        <li><a href="#on-the-relative-size-and-stable-rank-of-gradients">On the relative size and stable rank of gradients</a></li>
        <li><a href="#faster-feature-learning">Faster feature learning</a></li>
      </ul>
    </li>
    <li><a href="#how-to-cite">How to Cite</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="prologue">Prologue<a hidden class="anchor" aria-hidden="true" href="#prologue">#</a></h2>
<p>When training a neural network, our goal is to find parameters $\hat{W} = \{W_l\}_{1 \leq l \leq L}$ that minimize a loss function $L(\hat{W})$ with respect to some training data. This loss function is typically non-convex and/or intractable to compute exactly. Thus, we resort to iterative optimization algorithms to find a decent local minimum instead.</p>
<p>And every minute choice we make on how we approximate $L$ leads to a different optimization algorithm. To illustrate this simply, let&rsquo;s focus on one of the parameters $W_l$ and let&rsquo;s take the Taylor expansion of $L$ around $W_l$:
$$L(W_l + \Delta W_l) = L(W_l) + \langle\nabla L(W_l), \Delta W_l\rangle_F + \frac{1}{2} \langle\Delta W_l, H(W_l) \Delta W_l\rangle_F + \ldots,$$
where $\nabla L(W_l)$ is the gradient of $L$ at $W_l$, $H(W_l)$ is the Hessian of $L$ at $W_l$, and $\langle\cdot, \cdot\rangle_F$ is the Frobenius inner product:
$$\langle A, B\rangle_F = \text{tr}(A^T B) = \sum_{i,j} A_{ij}B_{ij}.$$</p>
<p>Our goal at each iteration then is to find $\Delta W_l$ that minimizes $L(W_l + \Delta W_l)$. I.e.:
$$\Delta W_l^* = \arg\min_{\Delta W_l} L(W_l + \Delta W_l)$$</p>
<p>And from here, we have three choies on how to approximate $L$ (and consequently $\Delta W_l^*$):</p>
<ol>
<li>
<p><strong>Second-order methods.</strong> Drop the third-order and subsequent terms in the Taylor expansion:
$$\Delta W_l^* = \arg\min_{\Delta W_l} \{\langle\nabla L(W_l), \Delta W_l\rangle_F + \frac{1}{2} \langle\Delta W_l, H(W_l) \Delta W_l\rangle_F\}$$
Then, using Newton&rsquo;s method, we get:
$$\Delta W_l^* = -H(W_l)^{-1} \nabla L(W_l)$$
However, computing the Hessian, let alone inverting it, is computationally expensive. Thus, second-order optimizers like Shampoo and CASPR resort to adding more assumptions to the structure of the Hessian to get the job done. We will discuss more on this in a future post.</p>
</li>
<li>
<p><strong>First-order with a soft norm penalty.</strong> Here, we approximate the second-order and subsequent terms in the Taylor expansion with a (squared-) norm penalty:
$$\Delta W_l^* = \arg\min_{\Delta W_l} \{\langle\nabla L(W_l), \Delta W_l\rangle_F + \frac{\lambda}{2} ||\Delta W_l||^2\},$$
for some norm $||\cdot||$ and some sharpness parameter $\lambda$ chosen a priori. This leads to the work of Bernstein &amp; Newhouse (2024) on Steepest Descent Under Operator Norms where they show that the optimal $\Delta W_l^*$ is:
$$\Delta W_l^* = -\frac{||\nabla L(W_l)||^{\dagger}}{\lambda}\text{dualizer}_{||\cdot||}(\nabla L(W_l)),$$
where $||\cdot||^{\dagger}$ is the dual norm of $||\cdot||$ and $$\text{dualizer}_{||\cdot||}(X) = \arg\max_{||T|| = 1}\langle X, T \rangle_F.$$</p>
</li>
<li>
<p><strong>First-order with a hard norm constraint.</strong> This is similar to the previous choice but we require that $\Delta W_l$ be of some fixed &ldquo;length&rdquo; $r$ with respect to the norm $||\cdot||$:
$$\Delta W_l^* = \arg\min_{\Delta W_l} \langle\nabla L(W_l), \Delta W_l\rangle_F \quad \text{s.t.} \quad ||\Delta W_l|| = r.$$
This leads to the work of Pethick et al. (2025) on Linear Minimization Oracle (LMO) over a norm ball.</p>
</li>
</ol>
<p>Now, notice that for $r = 1$, the only difference between the second and third choices is actually the scaling factor or the &ldquo;learning rate&rdquo;, the schedule of which we can tune separately. Either way, the crucial part is how we choose the norm $||\cdot||$&ndash;if we pick a different norm, we get a different class of optimizers.</p>
<h2 id="steepest-descent-under-operator-norms">Steepest Descent Under Operator Norms<a hidden class="anchor" aria-hidden="true" href="#steepest-descent-under-operator-norms">#</a></h2>
<p>Previous work by Bernstein &amp; Newhouse (2024) and Pethick et al. (2025) have already worked out the dualizers for different operator norms and how they give rise to different optimizers.</p>
<ol>
<li>
<p><strong>Frobenius Norm $||\cdot||_F$:</strong> The dual norm of the Frobenius norm is the Frobenius norm itself. And its dualizer is fairly simple:
$$
\begin{align*}
||\nabla L(W_l)||_F^{\dagger} &amp;= ||\nabla L(W_l)||_F\\
\text{dualizer}_{||\cdot||_F}(\nabla L(W_l)) &amp;= \frac{\nabla L(W_l)}{||\nabla L(W_l)||_F}
\end{align*}
$$
Thus, the update rule for steepest descent under the Frobenius norm is:
$$
\begin{align*}
\Delta W_l^* &amp;= -\frac{||\nabla L(W_l)||_F}{\lambda} \frac{\nabla L(W_l)}{||\nabla L(W_l)||_F}\\
\Delta W_l^* &amp;= -\frac{1}{\lambda} \nabla L(W_l)
\end{align*}
$$
which is just the update rule for Stochastic Gradient Descent (SGD).</p>
</li>
<li>
<p><strong>Max-of-Max Norm $||\cdot||_{1 \to \infty}$:</strong> A unit-length matrix under this norm is a matrix where all entries are $\pm 1$. And we can show that the unit-length matrix $T$ that maximizes the Frobenius inner product with the gradient $\nabla L(W_l)$ is the matrix whose entries are the signs of the entries of $\nabla L(W_l)$:
$$\text{dualizer}_{||\cdot||_{1 \to \infty}}(\nabla L(W_l)) = \text{sign}(\nabla L(W_l))$$
Thus, the update rule for steepest descent under the max-of-max norm is:
$$
\begin{align*}
\Delta W_l^* &amp;= -\frac{||\nabla L(W_l)||_{1 \to \infty}^\dagger}{\lambda} \text{sign}(\nabla L(W_l))\\
\Delta W_l^* &amp;= -\frac{1}{\hat{\lambda}} \frac{\nabla L(W_l)}{\sqrt{\nabla L(W_l) \odot \nabla L(W_l)}}
\end{align*}
$$
where $\hat{\lambda} = \frac{\lambda}{||\nabla L(W_l)||_{1 \to \infty}^\dagger}$ and $\odot$ is the element-wise (Hadamard) product. Note that this is the update rule for Adam without accumulation.</p>
</li>
<li>
<p><strong>Spectral Norm $||\cdot||_{2 \to 2}$:</strong> A unit-length matrix under this norm is a matrix whose singular values are all 1. And we can show that the unit-length matrix $T$ that maximizes the Frobenius inner product with the gradient $\nabla L(W_l)$ is the matrix whose singular vectors are also the singular vectors of $\nabla L(W_l)$. We will prove this more rigorously in the next section. But for now, the dualizer for the spectral norm is:
$$\text{dualizer}_{||\cdot||_{2 \to 2}}(\nabla L(W_l)) = UV^T,$$
where $\nabla L(W_l) = U\Sigma V^T$ is the singular value decomposition of $\nabla L(W_l)$. Thus, the update rule for steepest descent under the spectral norm is:
$$
\begin{align*}
\Delta W_l^* &amp;= -\frac{||\nabla L(W_l)||_{2 \to 2}^{\dagger}}{\lambda} UV^T\\
\Delta W_l^* &amp;= -\frac{1}{\hat{\lambda}} UV^T
\end{align*}
$$
where $\hat{\lambda} = \frac{\lambda}{||\nabla L(W_l)||^{\dagger}_{2 \to 2}}$
which is just the update rule for Muon.</p>
</li>
</ol>
<h2 id="steepest-descent-under-schatten-p-norms">Steepest Descent Under Schatten-$p$ Norms<a hidden class="anchor" aria-hidden="true" href="#steepest-descent-under-schatten-p-norms">#</a></h2>
<p>We can generalize the above to the Schatten-$p$ norms.</p>
<h3 id="schatten-p-norms">Schatten-$p$ Norms<a hidden class="anchor" aria-hidden="true" href="#schatten-p-norms">#</a></h3>
<blockquote>
<p><strong>Definition 1: Schatten-$p$ Norm.</strong> The Schatten-$p$ norm of a matrix $A$ is defined as:
$$||A||_p = \left(\sum_{i=1}^{\min(m, n)} |\sigma_i(A)|^p\right)^{1/p},$$
where $\sigma_i(A)$ are the singular values of $A$.</p>
</blockquote>
<p>In a sense, you can think of the Schatten-$p$ norm of $A$ as the $p$-norm of the singular values of $A.$</p>
<p><strong>Examples:</strong></p>
<ol>
<li>$p = 1$: The Nuclear norm, $||A||_{S_1} = \sum_{i=1}^{\min(m,n)} |\sigma_i(A)|$</li>
<li>$p = 2$: The Frobenius norm, $||A||_{S_2} = \left(\sum_{i=1}^{\min(m,n)} |\sigma_i(A)|^2\right)^{\frac{1}{2}} = ||A||_F$</li>
<li>$p = \infty$: The Spectral norm, $||A||_{S_{\infty}} = \max_{i} \sigma_i(A) = ||A||_{2 \to 2}$</li>
</ol>
<p>$(2)$ may be non-obvious to some, but here&rsquo;s a short proof:
$$
\begin{align*}
||A||_F &amp;= \sqrt{\sum_{ij} A_{ij}^2} = \sqrt{tr(A^TA)} = \sqrt{tr((U\Sigma V^T)^T(U\Sigma V^T))}\\
&amp;= \sqrt{tr(V \Sigma^2 V^T)} = \left(\sum_i \sigma_i(A)^2\right)^{\frac{1}{2}} = ||A||_{S_2}
\end{align*}
$$</p>
<h3 id="von-neumanns-trace-inequality">von Neumann&rsquo;s Trace Inequality<a hidden class="anchor" aria-hidden="true" href="#von-neumanns-trace-inequality">#</a></h3>
<p>And to find the dualizers for the Schatten-$p$ norms, we need the following inequality:</p>
<blockquote>
<p><strong>Theorem (von Neumann&rsquo;s Trace Inequality).</strong> Let $A$ and $B$ be two matrices. Then, the following inequality holds:
$$\text{tr}(A^TB) \leq \sum_{i=1}^{\min(m,n)} \sigma_i(A) \sigma_i(B),$$
where $\sigma_i(A)$ are the singular values of $A$. And equality holds if and only if $A$ and $B$ share singular vectors.</p>
</blockquote>
<h3 id="steepest-descent-under-schatten-p-norms-1">Steepest descent under Schatten-$p$ Norms<a hidden class="anchor" aria-hidden="true" href="#steepest-descent-under-schatten-p-norms-1">#</a></h3>
<p>Here, we derive the dualizer for an arbitrary Schatten-$p$ norm.</p>
<blockquote>
<p><strong>Proposition 2.</strong> The dualizer for the Schatten-$p$ norm is:
$$\text{dualizer}_{||\cdot||_{S_p}}(X) = U \frac{\text{diag}\left(\sigma_1(X)^{q-1}, \ldots, \sigma_{\min(m,n)}(X)^{q-1}\right)}{||X||_{S_q}^{q-1}} V^T$$
where $X = U\Sigma V^T$ is the singular value decomposition of $X$ and $\frac{1}{p} + \frac{1}{q} = 1$.</p>
</blockquote>
<blockquote>
<p><strong>Proof:</strong> For a given $X$, let $T^*$ be:
$$
\begin{align*}
T^* &amp;= \text{dualizer}_{||\cdot||_{S_p}}(X)\\
T^* &amp;= \arg\max_{||T||_{S_p} = 1} \langle X, T \rangle_F\\
T^* &amp;= \arg\max_{||T||_{S_p} = 1} \text{tr}(X^T T)
\end{align*}
$$
Then, from von Neumann&rsquo;s Trace Inequality, we know that $T^*$ must share singular vectors with $X$ and that:
$$T^* = \arg\max_{||T||_{S_p} = 1} \sum_{i=1} \sigma_i(X) \sigma_i(T)$$
Thus, our optimization problem reduces to
$$\max_{\{\sigma_i(T)\}} \sum_i \sigma_i(X) \sigma_i(T) \quad\text{s.t.}\quad \sum \sigma_i(T)^p = 1$$
which we can solve via Lagrange multipliers. See appendix for the full proof. For now, the solution is:
$$\sigma_i(T) = \frac{\sigma_i(X)^{q-1}}{||X||_{S_q}^{q-1}}$$
Hence,
$$T^* = \text{dualizer}_{||\cdot||_{S_p}}(X) = U \frac{\text{diag}\left(\sigma_1(X)^{q-1}, \ldots, \sigma_{\min(m,n)}(X)^{q-1}\right)}{||X||_{S_q}^{q-1}} V^T\quad\blacksquare$$</p>
</blockquote>
<p>The proof that the dual norm of the Schatten-$p$ norm is the Schatten-$q$ norm where $\frac{1}{p} + \frac{1}{q} = 1$ actually follows directly from here:</p>
<blockquote>
<p><strong>Corollary 3.</strong> The dual norm of the Schatten-$p$ norm is the Schatten-$q$ norm where $\frac{1}{p} + \frac{1}{q} = 1$.</p>
</blockquote>
<blockquote>
<p><strong>Proof:</strong> For a given $X$, we want to show that $$||X||_{S_p}^{\dagger} = ||X||_{S_q}$$
From the definition of the dual norm, we have:
$$
\begin{align*}
||X||_{S_p}^{\dagger} &amp;= \sup_{||T||_{S_p} \leq 1} \langle X, T \rangle_F\\
||X||_{S_p}^{\dagger} &amp;= \sup_{||T||_{S_p} \leq 1} \text{tr}(X^T T)
\end{align*}
$$
Following Proposition 2, we know that we can achieve the supremum by choosing $T = \text{dualizer}_{||\cdot||_{S_p}}(X)$. Thus,
$$
\begin{align*}
||X||_{S_p}^{\dagger} &amp;= \text{tr}\left(X^T U \frac{\text{diag}\left(\sigma_1(X)^{q-1}, \ldots, \sigma_{\min(m,n)}(X)^{q-1}\right)}{||X||_{S_q}^{q-1}} V^T\right)\\
&amp;= \sum_i \sigma_i(X) \frac{\sigma_i(X)^{q-1}}{||X||_{S_q}^{q-1}}\\
&amp;= \frac{1}{||X||_{S_q}^{q-1}} \sum_i \sigma_i(X)^q\\
&amp;= \frac{||X||_{S_q}^q}{||X||_{S_q}^{q-1}}\\
||X||_{S_p}^{\dagger} &amp;= ||X||_{S_q}\quad\blacksquare
\end{align*}
$$</p>
</blockquote>
<p>Finally,</p>
<blockquote>
<p><strong>Theorem 4.</strong> The update rule for steepest descent under the Schatten-$p$ norm is:
$$\Delta W_l^* = -\frac{1}{\hat{\lambda}} U \frac{\text{diag}\left(\sigma_1(\nabla L(W_l))^{q-1}, \ldots, \sigma_{\min(m,n)}(\nabla L(W_l))^{q-1}\right)}{||\nabla L(W_l)||_{S_q}^{q-1}} V^T$$
where $\hat{\lambda} = \frac{\lambda}{||\nabla L(W_l)||_{S_q}}$, $\nabla L(W_l) = U\Sigma V^T$ is the singular value decomposition of $\nabla L(W_l)$, and $\frac{1}{p} + \frac{1}{q} = 1$.</p>
</blockquote>
<p>The proof follows directly from Proposition 2 and Corollary 3.</p>
<h3 id="sanity-checks">Sanity Checks<a hidden class="anchor" aria-hidden="true" href="#sanity-checks">#</a></h3>
<p>Our results should match prior results for $p = 2, \infty$:</p>
<ol>
<li>
<p><strong>For $p = 2$, the Frobenius norm:</strong> $q = 2$ and $||\cdot||_{S_2}^\dagger = ||\cdot||_{S_2} = ||\cdot||_F$. Thus,
$$
\begin{align*}
\text{dualizer}_{||\cdot||_{S_2}}(X) &amp;= U \frac{\text{diag}\left(\sigma_1(X)^{2-1}, \ldots, \sigma_{\min(m,n)}(X)^{2-1}\right)}{||X||_{S_2}^{2-1}} V^T\\
\text{dualizer}_{||\cdot||_F}(X) &amp;= \frac{X}{||X||_F}
\end{align*}
$$
Thus,
$$
\begin{align*}
\Delta W_l^* &amp;= -\frac{||\nabla L(W_l)||_F}{\lambda} \frac{\nabla L(W_l)}{||\nabla L(W_l)||_F}\\
\Delta W_l^* &amp;= -\frac{1}{\lambda} \nabla L(W_l)
\end{align*}
$$</p>
</li>
<li>
<p><strong>For $p = \infty$, the Spectral norm:</strong> $q = 1$ and $||\cdot||_{S_\infty}^\dagger = ||\cdot||_{S_1}$. Thus,
$$
\begin{align*}
\text{dualizer}_{||\cdot||_{S_\infty}}(X) &amp;= U \frac{\text{diag}\left(\sigma_1(X)^{1-1}, \ldots, \sigma_{\min(m,n)}(X)^{1-1}\right)}{||X||_{S_1}^{1-1}} V^T\\
\text{dualizer}_{||\cdot||_{2 \to 2}}(X) &amp;= UV^T
\end{align*}
$$
Thus,
$$
\begin{align*}
\Delta W_l^* &amp;= -\frac{||\nabla L(W_l)||_{S_1}}{\lambda} UV^T\\
\Delta W_l^* &amp;= -\frac{1}{\hat{\lambda}} UV^T
\end{align*}
$$
where $\hat{\lambda} = \frac{\lambda}{||\nabla L(W_l)||_{S_1}}$.</p>
</li>
</ol>
<p>Both of which matches prior results. And as a fun exercise, try to prove that the dualizer for the Schatten-$1$ norm, or the Nuclear norm, results in a rank-$k$ matrix where $k$ is the multiplicity of the largest singular value.</p>
<h2 id="what-does-the-dualizer-actually-do">What Does the Dualizer Actually Do?<a hidden class="anchor" aria-hidden="true" href="#what-does-the-dualizer-actually-do">#</a></h2>
<p>We observe that steepest descent under the Schatten-$p$ norm very quickly starts to &ldquo;look like&rdquo; steepest descent under the Spectral norm as $p$ approaches $\infty$. This is probably why optimizers that merely approximately semi-orthogonalize the gradients like Sketching and Muon work so well in practice despite resulting in (relatively) high-variance of singular values post-dualization.</p>
<p>To support this, we show that the (1) variance of singular values, and the (2) relative size, and (3) stable rank of the gradients post-dualization under the Schatten-$p$ norm converge to those of the Spectral norm very quickly as $p$ approaches $\infty$. And in fact, at $p = 32$, the results are already very close to those of the Spectral norm.</p>
<h3 id="on-the-variance-of-singular-values">On the variance of singular values<a hidden class="anchor" aria-hidden="true" href="#on-the-variance-of-singular-values">#</a></h3>
<blockquote>
<p><strong>Proposition 5.</strong> The variance of the singular values post-dualization under the Schatten-$p$ Norm converges quadratically to $0$ as $p$ approaches $\infty$.</p>
</blockquote>
<blockquote>
<p><strong>Proof:</strong> Let $t_i$ be the $i$-th singular value post-dualization. From Proposition 2 earlier, we have
$$
\begin{align*}
t_i &amp;= \left(\frac{\sigma_i(\nabla L(W_l))}{||\nabla L(W_l)||_{S_q}}\right)^{q-1}\\
t_i &amp;= \exp\left((q-1)\ln\frac{\sigma_i(\nabla L(W_l))}{||\nabla L(W_l)||_{S_q}}\right)\\
t_i &amp;\approx 1 + (q-1)\ln\frac{\sigma_i(\nabla L(W_l))}{||\nabla L(W_l)||_{S_q}}
\end{align*}
$$
where the last line follows from first-order Taylor approximation of $t_i$. Thus, the mean and variance are:
$$
\begin{align*}
\mathbb{E}[t_i] &amp;\approx 1 + (q-1)\mathbb{E}\left[\ln\frac{\sigma_i(\nabla L(W_l))}{||\nabla L(W_l)||_{S_q}}\right]\\
\mathbb{E}[t_i] &amp;\approx 1 + (q-1)\ln\frac{\mathbb{E}[\sigma_i(\nabla L(W_l))]}{||\nabla L(W_l)||_{S_q}}\\
t_i - \mathbb{E}[t_i] &amp;\approx (q-1)\ln\left[\sigma_i(\nabla L(W_l)) - \mathbb{E}[\sigma_i(\nabla L(W_l))]\right]\\
Var[t_i] &amp;\approx (q-1)^2\mathbb{E}\left[\ln^2\left[\sigma_i(\nabla L(W_l)) - \mathbb{E}[\sigma_i(\nabla L(W_l))]\right]\right]\\
Var[t_i] &amp;\approx \frac{1}{(p-1)^2}\mathbb{E}\left[\ln^2\left[\sigma_i(\nabla L(W_l)) - \mathbb{E}[\sigma_i(\nabla L(W_l))]\right]\right]
\end{align*}
$$
Hence, the variance of the singular values post-dualization converges quadratically to $0$ as $p$ approaches $\infty$.</p>
</blockquote>
<p>Empirically, we can see this in the following plot. And at $p = 32$, the variance of the resulting singular values is already very close to $0$.
<img loading="lazy" src="/ponder/steepest-descent-schatten-p/var_sv_dualizer.png#center"></p>
<h3 id="on-the-relative-size-and-stable-rank-of-gradients">On the relative size and stable rank of gradients<a hidden class="anchor" aria-hidden="true" href="#on-the-relative-size-and-stable-rank-of-gradients">#</a></h3>
<blockquote>
<p><strong>Definition 6: Relative Size of a Gradient.</strong> Given a norm $||\cdot||$ chosen a priori, the relative size of a gradient-update $\Delta W$ relative to the parameter matrix $W$ is defined as:
$$\text{relsize}(\Delta W) = \frac{||\Delta W||}{||W||}$$</p>
</blockquote>
<blockquote>
<p><strong>Definition 7: Stable Rank.</strong> The stable rank of a matrix $A$ is defined as $$srank(A) = \frac{||A||_F^2}{||A||_{2 \to 2}^2}$$</p>
</blockquote>
<p>As we can see in the following plot, the raw gradients have very low-stable rank. But the stable rank of the gradients post-dualization under the Schatten-$p$ norm converges very quickly to that of the Spectral norm as $p$ approaches $\infty$.</p>
<p><img loading="lazy" src="/ponder/steepest-descent-schatten-p/srank_sv_dualizer.png#center"></p>
<p>One can interpret this as, for some large enough $p$, the dualized gradient is already very close to being &ldquo;maximal&rdquo; in a sense. And increasing $p$ further would only offer rapidly diminishing returns.</p>
<h3 id="faster-feature-learning">Faster feature learning<a hidden class="anchor" aria-hidden="true" href="#faster-feature-learning">#</a></h3>
<p>Why do we want &lsquo;maximal&rsquo; updates? I&rsquo;d love to dive deeper into this in a future post. But for now, I&rsquo;ll leave you with these:</p>
<ol>
<li><strong>Weight Erasure.</strong> Because the raw gradients are naturally &ldquo;small&rdquo; or have low stable rank, models trained with SGD, Adam, or similar optimizers tend to get &lsquo;stuck&rsquo; within a small region of the parameter space around the initialization (Lee et al., 2020; Jesus et al., 2021). On the other hand, optimizers like Muon that ramp up the stable rank of the gradients can quickly &rsquo;escape&rsquo; the init region and explore the parameter space more effectively. If you want to learn more about this, check out <a href="https://docs.modula.systems/examples/weight-erasure/" target="_blank">Bernstein&rsquo;s blog post on weight erasure</a> (2024).</li>
</ol>
<p><img loading="lazy" src="/ponder/steepest-descent-schatten-p/weight-erasure.png"></p>
<ol start="2">
<li><strong>Faster Feature Learning.</strong> Another reason we want &lsquo;maximal&rsquo; updates is that it allows the model to learn features faster. If our updates are too small, they would vanish at larger model widths. E.g., it&rsquo;s going to take you forever to learn a diverse features set on a 4096-wide model if your updates are merely rank-1. Ideally, our updates should &ldquo;grow&rdquo; with the model width. And, in a sense, this is what optimizers like Muon do.</li>
</ol>
<hr>
<p>That&rsquo;s it for now. Until next time!</p>
<hr>
<h2 id="how-to-cite">How to Cite<a hidden class="anchor" aria-hidden="true" href="#how-to-cite">#</a></h2>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bibtex" data-lang="bibtex"><span style="display:flex;"><span><span style="color:#0a0;text-decoration:underline">@misc</span>{cesista2025schattenp,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">author</span> = <span style="color:#a50">{Franz Louis Cesista}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">title</span> = <span style="color:#a50">{Steepest Descent Under Schatten-p Norms}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">year</span> = <span style="color:#a50">{2025}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">url</span> = <span style="color:#a50">{http://leloykun.github.io/ponder/steepest-descent-schatten-p/}</span>,
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<ol>
<li>Jeremy Bernstein and Laker Newhouse. “Old optimizer, new norm: An anthology.” arXiv preprint arXiv:2409.20325 (2024).</li>
<li>Jeremy Bernstein (2024). &ldquo;Weight erasure.&rdquo; Available at: <a href="https://docs.modula.systems/examples/weight-erasure/" target="_blank">https://docs.modula.systems/examples/weight-erasure/</a></li>
<li>Keller Jordan, Jeremy Bernstein, Brendan Rappazzo, @fernbear.bsky.social, Boza Vlado, Jiacheng You, Franz Cesista, Braden Koszarsky, and @Grad62304977. modded-nanogpt: Speedrunning the NanoGPT baseline. 2024. Available at: <a href="https://github.com/KellerJordan/modded-nanogpt" target="_blank">https://github.com/KellerJordan/modded-nanogpt</a>.</li>
<li>Keller Jordan, Yuchen Jin, Vlado Boza, Jiacheng You, Franz Cesista, Laker Newhouse, and Jeremy Bernstein (2024). Muon: An optimizer for hidden layers in neural networks. Available at: <a href="https://kellerjordan.github.io/posts/muon/" target="_blank">https://kellerjordan.github.io/posts/muon/</a>.</li>
<li>Vineet Gupta, Tomer Koren, Yoram Singer (2018). Shampoo: Preconditioned Stochastic Tensor Optimization. URL <a href="https://arxiv.org/abs/1802.09568" target="_blank">https://arxiv.org/abs/1802.09568</a></li>
<li>Rohan Anil et al. “Scalable second order optimization for deep learning.” arXiv preprint arXiv:2002.09018 (2020).</li>
<li>Surya, S., Duvvuri, Devvrit, F., Anil, R., Hsieh, C., &amp; Dhillon, I.S. (2024). Combining Axes Preconditioners through Kronecker Approximation for Deep Learning. International Conference on Learning Representations.</li>
<li>Thomas Pethick, Wanyun Xie, Kimon Antonakopoulos, Zhenyu Zhu, Antonio Silveti-Falls, Volkan Cevher (2025). Training Deep Learning Models with Norm-Constrained LMOs. Available at: <a href="https://arxiv.org/abs/2502.07529" target="_blank">https://arxiv.org/abs/2502.07529</a>.</li>
<li>David E Carlson, Edo Collins, Ya-Ping Hsieh, Lawrence Carin, Volkan Cevher (2015). Preconditioned Spectral Descent for Deep Learning. Advances in Neural Information Processing Systems 28 (NIPS 2015)</li>
<li>Lee, Jaehoon, et al. “Wide Neural Networks of Any Depth Evolve as Linear Models under Gradient Descent.” Journal of Statistical Mechanics: Theory and Experiment, vol. 2020, no. 12, Dec. 2020, p. 124002. Crossref, <a href="https://doi.org/10.1088/1742-5468/abc62b" target="_blank">https://doi.org/10.1088/1742-5468/abc62b</a>.</li>
<li>Jesus, Ricardo J., et al. “Effect of Initial Configuration of Weights on Training and Function of Artificial Neural Networks.” Mathematics, vol. 9, no. 18, Sept. 2021, p. 2246. Crossref, <a href="https://doi.org/10.3390/math9182246" target="_blank">https://doi.org/10.3390/math9182246</a>.</li>
<li>Greg Yang and James B. Simon and Jeremy Bernstein (2024). A Spectral Condition for Feature Learning. Available at: <a href="https://arxiv.org/abs/2310.17813" target="_blank">https://arxiv.org/abs/2310.17813</a>.</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://leloykun.github.io/tags/machine-learning/">Machine Learning</a></li>
      <li><a href="https://leloykun.github.io/tags/muon/">Muon</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Steepest Descent Under Schatten-p Norms on x"
            href="https://x.com/intent/tweet/?text=Steepest%20Descent%20Under%20Schatten-p%20Norms&amp;url=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-schatten-p%2f&amp;hashtags=MachineLearning%2cMuon">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Steepest Descent Under Schatten-p Norms on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-schatten-p%2f&amp;title=Steepest%20Descent%20Under%20Schatten-p%20Norms&amp;summary=Steepest%20Descent%20Under%20Schatten-p%20Norms&amp;source=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-schatten-p%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Steepest Descent Under Schatten-p Norms on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-schatten-p%2f&title=Steepest%20Descent%20Under%20Schatten-p%20Norms">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Steepest Descent Under Schatten-p Norms on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-schatten-p%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Steepest Descent Under Schatten-p Norms on whatsapp"
            href="https://api.whatsapp.com/send?text=Steepest%20Descent%20Under%20Schatten-p%20Norms%20-%20https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-schatten-p%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Steepest Descent Under Schatten-p Norms on telegram"
            href="https://telegram.me/share/url?text=Steepest%20Descent%20Under%20Schatten-p%20Norms&amp;url=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-schatten-p%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Steepest Descent Under Schatten-p Norms on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Steepest%20Descent%20Under%20Schatten-p%20Norms&u=https%3a%2f%2fleloykun.github.io%2fponder%2fsteepest-descent-schatten-p%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://leloykun.github.io/">Franz Louis Cesista</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
