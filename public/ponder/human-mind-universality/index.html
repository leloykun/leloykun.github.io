<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>The Human Mind May Be Universal | Franz Louis Cesista</title>
<meta name="keywords" content="Machine Learning, Brain, Philosophy">
<meta name="description" content="Years of experience in building artificial minds led me to believe that these AIs may end up seeming more &#39;human&#39; than we currently imagine them to be.">
<meta name="author" content="Franz Louis Cesista">
<link rel="canonical" href="https://leloykun.github.io/ponder/human-mind-universality/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f1e4501a2ac2bf9fff5dc0c77f152affb825b371cb176acfcf9201015d59b4d4.css" integrity="sha256-8eRQGirCv5//XcDHfxUq/7gls3HLF2rPz5IBAV1ZtNQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://leloykun.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://leloykun.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://leloykun.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://leloykun.github.io/apple-touch-icon.png">

<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://leloykun.github.io/ponder/human-mind-universality/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="The Human Mind May Be Universal" />
<meta property="og:description" content="Years of experience in building artificial minds led me to believe that these AIs may end up seeming more &#39;human&#39; than we currently imagine them to be." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://leloykun.github.io/ponder/human-mind-universality/" />
<meta property="og:image" content="https://leloykun.github.io/cover.jpg" /><meta property="article:section" content="ponder" />
<meta property="article:published_time" content="2023-12-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-12-10T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://leloykun.github.io/cover.jpg" />
<meta name="twitter:title" content="The Human Mind May Be Universal"/>
<meta name="twitter:description" content="Years of experience in building artificial minds led me to believe that these AIs may end up seeming more &#39;human&#39; than we currently imagine them to be."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Ponder",
      "item": "https://leloykun.github.io/ponder/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "The Human Mind May Be Universal",
      "item": "https://leloykun.github.io/ponder/human-mind-universality/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "The Human Mind May Be Universal",
  "name": "The Human Mind May Be Universal",
  "description": "Years of experience in building artificial minds led me to believe that these AIs may end up seeming more 'human' than we currently imagine them to be.",
  "keywords": [
    "Machine Learning", "Brain", "Philosophy"
  ],
  "articleBody": " What we consider today as characteristically “human” thought and consciousness may just be a valley in a large attractor basin of all possible minds.\nIf there’s an alien civilization out there, they may not think that differently from us. Likewise, “human-level” and superhuman AIs in the future may end up seeming more “human” than we currently imagine them to be. Instead of being Lovecraftian horrors as we see them on movies, they’ll probably just have the same philosophical questions, the same moral dilemmas, and perhaps even the same worries as us.\nThere are two shards of evidence that led me to this idea, the first is an empirical observation while the second is more theoretical:\n1. At scale, different kinds of minds are practically just the same In the field of Machine Learning (colloquially equated with Artificial Intelligence), we have what we call “model architectures”—think of them as “brain structures” but for AIs. And the strange thing is pretty much every big-enough model architecture trained on the same dataset for an equally long time converges to the same mapping. They generate almost the same text, images, “hallucinations”, probability distributions, etc.\nThink of it like this: if our pets have large-enough brains relative to their body size, their thoughts would not be that different from ours. We’d be able to communicate with them with little to no friction. Now apply this logic to AIs and aliens…\nBut why is this so?\n2. Local minima are rare in higher dimensions Biological minds tend to minimize energy consumption. This is because if an animal’s brain consumes more energy than it needs, then that animal would need to hunt more or be in the open to forage more food just to continue thinking—this puts them in more risky situations and thus more chances of dying.\nLikewise, we train artificial minds to minimize what we call “loss function”, which we can interpret as a form of energy. For example, the mean-squared error in linear regression is equivalent to the potential energy of the corresponding stick-and-springs model. I’ll discuss more about this in a future article.\nThe thing is: at higher dimensions, these energy landscapes usually only have a unique, large attractor basin. That, or multiple attractor basins with zero-cost bridges between them.\nThis is because, for a point to be a local minimum in an energy landscape, all eigenvalues of the hessian (a higher dimensional analogue of the second derivative) at that point has to be positive. And the more dimensions you have, the less likely it is for all of the eigenvalues to be positive. Thus, at scale, it’s very unlikely to get trapped in a local minimum.\nMy point here is that we’re likely not as special as we think we are. What we consider as “uniquely human” today may not be so when artificial general intelligences come along. Heck, if aliens ever find us, they’d probably think we’re just a younger version of them unlucky enough to ascend to consciousness a bit later.\nIn the next article, I’ll write about geometric and physical interpretations of the building blocks of machine learning. If you don’t want to miss it, subscribe now!\n",
  "wordCount" : "528",
  "inLanguage": "en",
  "image":"https://leloykun.github.io/cover.jpg","datePublished": "2023-12-10T00:00:00Z",
  "dateModified": "2023-12-10T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Franz Louis Cesista"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://leloykun.github.io/ponder/human-mind-universality/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Franz Louis Cesista",
    "logo": {
      "@type": "ImageObject",
      "url": "https://leloykun.github.io/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://leloykun.github.io/" accesskey="h" title="Franz Louis Cesista">
             
                <img src="https://leloykun.github.io/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Franz Louis Cesista</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://leloykun.github.io/cv.pdf" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/papers/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/personal-projects/" title="Personal Projects">
                    <span>Personal Projects</span>
                </a>
            </li>
            <li>
                <a href="https://leloykun.github.io/ponder/" title="Ponder (Blog)">
                    <span>Ponder (Blog)</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      The Human Mind May Be Universal
    </h1>
    <div class="post-meta"><span title='2023-12-10 00:00:00 +0000 UTC'>December 10, 2023</span>&nbsp;&middot;&nbsp;Franz Louis Cesista&nbsp;&middot;&nbsp;<a href="https://ponder.substack.com/p/the-human-mind-may-be-universal" rel="noopener noreferrer" target="_blank">Crossposted on Ponder</a>

</div>
  </header> 
  <div class="post-content"><p><img loading="lazy" src="cover.jpg" alt="cover"  />
</p>
<blockquote>
<p>What we consider today as characteristically &ldquo;human&rdquo; thought and consciousness may just be a valley in a large attractor basin of all possible minds.</p>
</blockquote>
<p>If there&rsquo;s an alien civilization out there, they may not think that differently from us. Likewise, &ldquo;human-level&rdquo; and superhuman AIs in the future may end up seeming more &ldquo;human&rdquo; than we currently imagine them to be. Instead of being Lovecraftian horrors as we see them on movies, they’ll probably just have the same philosophical questions, the same moral dilemmas, and perhaps even the same worries as us.</p>
<p>There are two shards of evidence that led me to this idea, the first is an empirical observation while the second is more theoretical:</p>
<h2 id="1-at-scale-different-kinds-of-minds-are-practically-just-the-same">1. At scale, different kinds of minds are practically just the same</h2>
<p>In the field of Machine Learning (colloquially equated with Artificial Intelligence), we have what we call &ldquo;model architectures&rdquo;—think of them as &ldquo;brain structures&rdquo; but for AIs. And the strange thing is pretty much every big-enough model architecture trained on the same dataset for an equally long time converges to the same mapping. They generate almost the same text, images, &ldquo;hallucinations&rdquo;, probability distributions, etc.</p>
<p>Think of it like this: if our pets have large-enough brains relative to their body size, their thoughts would not be that different from ours. We’d be able to communicate with them with little to no friction. Now apply this logic to AIs and aliens&hellip;</p>
<p>But why is this so?</p>
<h2 id="2-local-minima-are-rare-in-higher-dimensions">2. Local minima are rare in higher dimensions</h2>
<p>Biological minds tend to minimize energy consumption. This is because if an animal&rsquo;s brain consumes more energy than it needs, then that animal would need to hunt more or be in the open to forage more food just to continue thinking—this puts them in more risky situations and thus more chances of dying.</p>
<p>Likewise, we train artificial minds to minimize what we call &ldquo;loss function&rdquo;, which we can interpret as a form of energy. For example, the mean-squared error in linear regression is equivalent to the potential energy of the corresponding stick-and-springs model. I&rsquo;ll discuss more about this in a future article.</p>
<p>The thing is: at higher dimensions, these energy landscapes usually only have a unique, large attractor basin. That, or multiple attractor basins with zero-cost bridges between them.</p>
<p>This is because, for a point to be a local minimum in an energy landscape, all eigenvalues of the hessian (a higher dimensional analogue of the second derivative) at that point has to be positive. And the more dimensions you have, the less likely it is for all of the eigenvalues to be positive. Thus, at scale, it&rsquo;s very unlikely to get trapped in a local minimum.</p>
<hr>
<p>My point here is that we&rsquo;re likely not as special as we think we are. What we consider as &ldquo;uniquely human&rdquo; today may not be so when artificial general intelligences come along. Heck, if aliens ever find us, they&rsquo;d probably think we&rsquo;re just a younger version of them unlucky enough to ascend to consciousness a bit later.</p>
<hr>
<p>In the next article, I’ll write about geometric and physical interpretations of the building blocks of machine learning. If you don’t want to miss it, subscribe now!</p>
<center><iframe src="https://ponder.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe></center>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://leloykun.github.io/tags/machine-learning/">Machine Learning</a></li>
      <li><a href="https://leloykun.github.io/tags/brain/">Brain</a></li>
      <li><a href="https://leloykun.github.io/tags/philosophy/">Philosophy</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    &copy; 2025 Franz Louis Cesista
    <span>
    &middot;  Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
